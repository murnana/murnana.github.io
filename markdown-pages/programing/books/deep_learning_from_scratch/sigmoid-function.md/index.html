<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><style data-href="/styles.1ddd39c799ecca2c60ce.css">*{margin:0;padding:0;border:0;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Open Sans,Helvetica Neue,sans-serif;list-style:inside}.clearfix:after{content:"";clear:both;display:inherit}.layout{width:100vw;max-width:none;height:100vh;max-height:none;overflow-x:hidden;overflow-y:auto}.layout>main{margin-right:3.6rem;padding:2rem 0 2rem 2rem;width:calc(100vw - 6.6rem);max-width:none;overflow-wrap:break-word}.layout>button.menu{width:3rem;max-width:none;height:3rem;max-height:none;position:fixed;right:0;top:0;opacity:.2;background-color:#fff;border:.3rem double #000;border-radius:.5rem;text-align:center;font-size:.7rem;color:#000}.layout>button.menu:hover{opacity:1}.layout>nav.menu{width:100vw;max-width:none;height:100vh;max-height:none;position:fixed;z-index:1;overflow-y:auto;overflow-wrap:break-word}.layout>nav.menu>.dialog{position:fixed;top:0;right:0;max-width:calc(100vw - 4.6rem);max-height:calc(100vh - 4.6rem);margin:.2rem;padding:1rem;background-color:#fff;border:.3rem double #000;border-radius:.5rem;text-align:left;font-size:100%;color:grey}.layout>nav.menu>ul>li{list-style:none}.layout>nav.menu>ul>li>*{text-decoration:none}.layout>nav.menu>ul>li>:link{color:#000}</style><meta name="generator" content="Gatsby 2.20.27"/><link as="script" rel="preload" href="/webpack-runtime-bd764cbdbc8d0cacfb43.js"/><link as="script" rel="preload" href="/framework-e5dc7793c9d7bc935506.js"/><link as="script" rel="preload" href="/styles-1c3c06048fccead674b8.js"/><link as="script" rel="preload" href="/app-d52bcde7c87186f41496.js"/><link as="script" rel="preload" href="/component---src-templates-markdown-pages-template-js-9e0b5e152df8c2c5a7b4.js"/><link as="fetch" rel="preload" href="/page-data/markdown-pages/programing/books/deep_learning_from_scratch/sigmoid-function.md/page-data.json" crossorigin="anonymous"/><link as="fetch" rel="preload" href="/page-data/app-data.json" crossorigin="anonymous"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="layout"><button class="menu">Menu</button><main><article><h1>ニューラルネットワーク - シグモイド関数</h1><div><p>入力信号の総和を出力信号に変換する関数を、一般に <strong>活性化関数</strong>
(activation function)という。
活性化関数には候補となる関数がいくつかある。</p>
<p>パーセプトロンの場合は、閾値を境にして値が変わるため、「ステップ関数」や「階段関数」と呼ばれる</p>
<p>活性化関数はほかにもある。 今回は <strong>シグモイド関数</strong> (sigmoid
function)について。</p>
<h1>シグモイド関数</h1>
<p>シグモイド関数の一般項は</p>
<p>$$h(x) = \frac{1 + \exp(-x)}{1}$$</p>
<p>ここでいう exp とは <strong>ネイピア数</strong> のことを指す。</p>
<p>::: {.plot}
import numpy import matplotlib.pylab as plt</p>
<p>""" ステップ関数 :param numpy.array: x """ def step_function(x):
y = x > 0 # 配列 X の各要素を比較した結果の配列を Y に入れる return
y.astype(numpy.int) # Y の各要素 boolean を int がたに変換</p>
<p>""" シグモイド関数 :param numpy.array: x """ def sigmoid(x):
return 1 / (1 + numpy.exp(-x)) # exp = 指数関数のこと</p>
<p>if __name__ == "__main__":</p>
<p>: x = numpy.arange(-5.0, 5.0, 0.1) # 0.1 刻みで、-5.0 ~ 5.0 の配列 y1
= step_function(x) y2 = sigmoid(x) plt.plot(x, y1, linestyle =
'--', label = 'step') plt.plot(x, y2, label = 'sigmoid')
plt.ylim(-0.1, 1.1) # y 軸の範囲 plt.show()
:::</p>
<h1>Rectified Linear Unit; ReLU (正規化線形関数、ランプ関数)</h1>
<p>ReLU は、 <strong>0 未満の時は 0、0 以上の時は 0 以上の値</strong> を出力する関数</p>
<p>$$
h(x) = \left{ \begin{array}{ll}
x &#x26; (x > 0) \
0 &#x26; (x \leq 0)
\end{array} \right.
\end{aligned}$$</p>
<pre><code class="language-{.python}">def relu(x):
    return np.maximum(0, x)
</code></pre>
<h1>3層ニューラルネットワークの実装</h1>
<p>行列とは何かは知っているので省略！</p>
<pre><code class="language-{.python}">import numpy
import matplotlib.pylab as plt
import step_and_sigmoid


"""
恒常関数
値をそのまま返す関数のこと
:param numpy.array: x
"""
def identity_function(x):
    return x



"""
ネットワークの構築
重みとバイアスの初期化をします
…本当は学習結果で分かった重みを突っ込む気がする
"""
def init_network():
    network = {}
    # 1層目の重みとバイアス
    network['W1'] = numpy.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])
    network['b1'] = numpy.array([0.1, 0.2, 0.3])

    # 2層目の重みとバイアス
    network['W2'] = numpy.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])
    network['b2'] = numpy.array([0.1, 0.2])

    # 3層目の重みとバイアス
    network['W3'] = numpy.array([[0.1, 0.3], [0.2, 0.4]])
    network['b3'] = numpy.array([0.1, 0.2])

    return network


"""
入力からニューラルネットワークを通じて出力する
"""
def forward(network, x):
    # 1層目のニューロンを計算する
    a1 = numpy.dot(x, network['W1']) + network['b1']
    z1 = step_and_sigmoid.sigmoid(a1)

    # 2層目のニューロンを計算する
    a2 = numpy.dot(z1, network['W2']) + network['b2']
    z2 = step_and_sigmoid.sigmoid(a2)

    # 3層目のニューロンを計算する
    a3 = numpy.dot(z2, network['W3']) + network['b3']
    y = identity_function(a3)

    return y


if __name__ == "__main__":
    network = init_network()
    print(f'network is {network}')

    x = numpy.array([1.0, 0.5])
    print(f'x = {x}')

    y = forward(network, x)
    print(f'y = {y}')
</code></pre>
<h1>学習問題の種類</h1>
<p>補足と言いつつ実は大事なのでは</p>
<h2>分類問題</h2>
<p>データがどのクラスに属するのか。
例えば、人の画像から性別を判断する、など</p>
<p>-</p>
<pre><code>ソフトマックス

:   全ての入力信号から影響を受ける出力信号を1つ出す
    出力は合計すると1になることから、「確率」として解釈することができる
</code></pre>
<h2>回帰問題</h2>
<p>データから(連続的な)数値を予測する問題。
例えば、人の画像から体重を予測する、など</p>
<p>-</p>
<pre><code>恒常関数

:   入力信号1つに対して、出力信号を1つ出す
</code></pre>
<h1>指数(exp)の扱いに注意</h1>
<p>指数をそのまま扱うと、オーバーフローで :py<code>infinity</code>{.interpreted-text
role="const"} や ::py<code>nan</code>{.interpreted-text role="const"}
が出てきたりする
Python2かPython3かによっても最大値が変わるので、都度確認したほうが良い。</p>
<p>今回はPython3なので...</p>
<ul>
<li>整数は(一応)無制限</li>
<li>浮動小数点はCのdouble($2.225074 * 10^{-308} &#x3C; x &#x3C; 1.797693 * 10^{308}$)</li>
</ul>
<p>数値の型はほかにもあるけれど割合...</p>
<p>::: {.seealso}
<a href="http://enajet.air-nifty.com/blog/2011/09/python-9a0e-1.html">Python ：　整数最大値、辞書項目数の最大値:
enajet</a></p>
<p><a href="https://docs.python.org/ja/3/library/stdtypes.html#typesnumeric">4. 組み込み型 --- Python 3.6.5 ドキュメント</a></p>
<p>:   4.4. 数値型 int, float, complex</p>
<p><a href="http://www.cc.kyoto-su.ac.jp/~yamada/programming/float.html">浮動小数点数型と誤差</a>
:::</p>
<h1>出力層のニューロン数</h1>
<p>出力層は一般的に、分類したい種類(クラス)の数に設定する</p>
<h1>MNIST を使用した実践</h1>
<p>Python3系ではPILは使えない(おかしい、Python3の書籍のはず...)
ので、pillowを入れる。</p>
<pre><code class="language-{.shell}">$ pip install pillow
</code></pre>
<p>このドキュメントではpipenvを使っているので</p>
<pre><code class="language-{.shell}">$ pipenv install pillow
</code></pre>
<p>::: {.seealso}
<a href="https://qiita.com/ukwksk/items/483d1b9e525667b77187">python3系でのPython Image
Libraryの使用方法</a>
:::
$$</p></div></article></main></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/markdown-pages/programing/books/deep_learning_from_scratch/sigmoid-function.md";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"app":["/app-d52bcde7c87186f41496.js"],"component---src-pages-hobby-index-js":["/component---src-pages-hobby-index-js-a6ca140d9313836e4b07.js"],"component---src-pages-hobby-sdorica-js":["/component---src-pages-hobby-sdorica-js-7f98227ffeb140465681.js"],"component---src-pages-index-js":["/component---src-pages-index-js-50ddbdebe6320eab3f9b.js"],"component---src-templates-markdown-pages-template-js":["/component---src-templates-markdown-pages-template-js-9e0b5e152df8c2c5a7b4.js"]};/*]]>*/</script><script src="/component---src-templates-markdown-pages-template-js-9e0b5e152df8c2c5a7b4.js" async=""></script><script src="/app-d52bcde7c87186f41496.js" async=""></script><script src="/styles-1c3c06048fccead674b8.js" async=""></script><script src="/framework-e5dc7793c9d7bc935506.js" async=""></script><script src="/webpack-runtime-bd764cbdbc8d0cacfb43.js" async=""></script></body></html>